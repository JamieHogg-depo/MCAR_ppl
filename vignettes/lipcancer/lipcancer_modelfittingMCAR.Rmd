---
title: "Efficient Leroux model in Stan"
author:
  name: "By James Hogg - 2023"
output: 
  html_document:
    toc: true
bibliography: bib.bib
csl: research-in-number-theory.csl
editor_options: 
  chunk_output_type: console
---

\newcommand{\lb}[1]{\left( #1 \right)}
\newcommand{\jdist}[2]{\text{#1}\left( #2 \right)}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Use https://github.com/mbjoseph/CARstan/blob/master/README.Rmd as an example

## Load packages ## ------------------------------------------------------------
library(knitr)
library(tidyverse)
library(sf)
library(spdep)
library(mvtnorm)
library(rstan)
rstan_options(auto_write = TRUE)
library(patchwork)
library(CARBayes)     # A package for fitting CAR models 
library(CARBayesdata) # A package with the Scottish lip cancer data
library(igraph)       # check that weight matrices are entirely connected
library(posterior)
rm(list = ls())

# Source functions
#setwd("vignettes/lipcancer/")
source("../../src/funs.R")
```

# Introduction

This document details the Leroux conditional autoregressive (LCAR) models in Stan. Building on previous work in sparse implementations of CAR models in Stan, we show that our approach can give considerable efficiency gains, scaling better for large spatial data sets.This vignette shows how the multivariate LCAR implementation given here can be used in the univariate case. 

# The Leroux spatial model

Although CAR models have been used for decades to model the spatial dependence between lattice spatial data, the model proposed by Leroux [@RN366] has gained considerable attention given its nice properties. Suppose we have aggregated disease count data $y_1, y_2, \dots, y_M$ at $M$ locations, and we expect that neighbouring locations will have similar counts. Standard disease mapping assumes a Poisson likelihood of the form:

$$
y_i \sim \jdist{Poisson}{\jdist{exp}{\beta + \phi_i + \jdist{log}{E_i}}}
$$

where $\beta$ is the overall intercept, $\phi_i$ are the spatial random effects which follow a Leroux prior (discussed below) and $E_i$ gives the expected counts which are included to account for differences in expected values or exposures in the small areas. 

Using the Leroux CAR prior for $\boldsymbol{\phi} = \lb{ \phi_1, \dots, \phi_M }$, results in a multivariate Gaussian distribution of the form:

$$
\boldsymbol{\phi} \sim \jdist{MVN}{\boldsymbol{0}, \boldsymbol{\Omega}^{-1}}
$$

where $\boldsymbol{\Omega} = \frac{1}{\tau^2}[\rho\lb{ \boldsymbol{D} - \boldsymbol{W} } + (1-\rho)]$ is the precision matrix of size $M \times M$. With some simplifications,

$$
\begin{align}
\boldsymbol{\Omega} &= \frac{1}{\tau^2} \left[ \rho\lb{ \boldsymbol{D} - \boldsymbol{W} } + (1-\rho) \right]
\\
\boldsymbol{\Omega} &= \frac{1}{\tau^2} \left[ \boldsymbol{I} - \rho \boldsymbol{C} \right]
\end{align}
$$
where $\boldsymbol{C} = \boldsymbol{I} - \boldsymbol{D} + \boldsymbol{W}$. Assume the following:

- $\boldsymbol{D}$: an $M \times M$ diagonal matrix with the number of neighbors for each area
- $\boldsymbol{I}$: an $M \times M$ identity matrix
- $\rho$: a spatial autocorrelation parameter that controls the level of spatial dependence ($\rho = 0$ implies spatial independence and $\rho = 1$ collapses to an intrinsic CAR (ICAR) prior which has already been implemented in `Stan`)
- $\boldsymbol{W}$: the $M \times M$ binary contiguity adjacency matrix. $W_{ij} = 1$ if and only if area $i$ is a neighbor of area $j$. All other entries of $\boldsymbol{W}$ are $0$. 
- $\tau$ is the marginal standard deviation of the Leroux random effects

To facilitate a fair comparison with `CARBayes`, we assume the following priors throughout the analysis.
$$
\begin{align}
\tau^2 &\sim \jdist{Inverse-Gamma}{1,0.5}
\\
\rho &\sim \jdist{Uniform}{0,1}
\\
\beta &\sim \jdist{N}{0,1}
\end{align}
$$



## A poisson specification

```{r, compile_chunk, echo = FALSE}
# compile Stan model
unlink("*.rds")
s_comp <- stan_model(file = "efficient.stan")
sn_comp <- stan_model(file = "naive.stan")
```


# Example: Scottist lip cancer data

Like many vignettes on disease mapping, to demonstrate this approach we will use the Scottish lip cancer data example. This data set includes observed lip cancer case counts at 56 spatial units in Scotland, with an expected number of cases to be used as an offset. The model structure is identical to the Poisson model outlined above.

```{r}
# Load data from CARBayesdata package
data(lipdata)
data(lipdbf)
data(lipshp)
lipdbf$dbf <- lipdbf$dbf[ ,c(2,1)]
data <- st_as_sf(combine.data.shapefile(data=lipdata, shp=lipshp, dbf=lipdbf))

# create weight matrices
W <- nb2mat(poly2nb(data), zero.policy = FALSE, style = "B")

# create design matrix
data$scaled_x <- c(scale(data$pcaff))
X <- model.matrix(~data$scaled_x)
```

## Standard CARBayes implementation: LCAR with `S.CARleroux`

First, we'll fit the Poisson Leroux model using `CARBayes`. Along with this vignette we have supplied a set of functions that we access by calling the list `myfuns`. These user-written functions extend the `S.CARleroux` function from `CARBayes` to allow for 4 chains. In an attempt to harbor a fair comparison, we've allowed the component-wise sampler implemented in `CARBayes` to use three times the warmup we'll employ in `rstan` as burnin.  

```{r}
m_s <- Sys.time()
cb_fit <- myfuns$fitLeroux_mc(observed ~ offset(log(expected)) + scaled_x, 
                              data = data, family = "poisson",
                              burnin = 4000, n.sample = 6000, 
                              thin = 1, W = W,
                              n.chains = 4) # n.chains not native to CARBayes
(cb_rt <- as.numeric(Sys.time() - m_s, units = "mins"))

# summarise draws
cb_summ <- myfuns$summaryLeroux_mc(cb_fit) %>% 
  mutate(bess_pm = ess_bulk/cb_rt,
         tess_pm = ess_tail/cb_rt)
```

## Naive Stan implementation: LCAR with `multi_normal_prec`

Stan model:
```{r, eval = FALSE}
"
data{
	int<lower=1> M; 				// number of areas
	int y[M];
	vector[M] E;
	matrix[M, 2] X;
	matrix[M, M] C;
}
transformed data{
	vector[M] zeros = rep_vector(0, M);
}
parameters{
	real<lower=0> tau2; // marginal variance
	real<lower=0,upper=1> rho;
	vector[2] bbeta;
	vector[M] phi;
}
model{
	// likelihood model
	y ~ poisson_log(log(E) + X * bbeta + phi);
	
	// priors
	tau2 ~ inv_gamma( 1, 0.5); // marginal variance
	bbeta ~ std_normal( );
	rho ~ uniform( 0, 1);
	
	// naive implementation of leroux
	phi ~ multi_normal_prec( zeros, ( 1.0 ./ tau2 ) * add_diag( - rho * C, 1 ) );
}
"
```

Fit model:
```{r, naive_fit}
# data list
C_for_stan <- myfuns$prep4MCAR(W, type = "lcar")
d_stan <- list(M = nrow(data), y = data$observed,
               E = data$expected, C = C_for_stan$C,
               X = X)

# fit the Leroux model
m_s <- Sys.time()
sn_fit <- sampling(object = sn_comp, 
                  data = d_stan, 
                  chains = 4, iter = 6000, warmup = 4000,
                  cores = 4, refresh = 0)
(sn_rt <- as.numeric(Sys.time() - m_s, units = "mins"))

# summarize results
sn_its <- rstan::extract(sn_fit)
sn_summ <- summarise_draws(sn_fit) %>% 
  mutate(bess_pm = ess_bulk/sn_rt,
         tess_pm = ess_tail/sn_rt)
```

## Efficient Stan implementation: LCAR with `MLCAR`

Stan model:
```{r, eval=FALSE}
"
functions{
/**
* Log probability density of the multivariate leroux CAR model
* @param x_mat input pars in matrix form (M x K)
* @param rho Spatial dependence parameter
* @param C matrix that represents spatial neighborhood 
* @param C_eigenvalues eigenvalues of C
* @param M number of areas
* @param K number of factors
**
@return Log probability density
*/
real MLCAR_lpdf(
    matrix x_mat,               // input pars in matrix form M x K
    real rho,                   // spatial smoothing parameter
    matrix Omega_R,             // Precision matrix for factors
    matrix Sigma_R,             // Covariance matrix for factors
    vector C_w , 
    int [] C_v , 
    int [] C_u , 
    int [] offD_id_C_w ,        // indexes for off diagonal terms
    int [] D_id_C_w ,       // indexes for diagonal terms - length M
    vector C_eigenvalues,       // eigenvalues for C
    int M,                      // Number of areas
    int K) {                    // Number of factors
        vector[M] ldet_C;
        vector[K] log_d_Sigma_R_chol = log(diagonal(cholesky_decompose(Sigma_R)));
        matrix[K, M] A_R = Omega_R * x_mat';
        // Alternative specification for A_S
        // Omega_S as sparse matrix multiplied by columns of x_mat 
        // using crs_matrix_times_vector
            vector [ num_elements(C_w) ] ImrhoC;
            matrix[M, K] A_S;
            // Multiple off-diagonal elements by rho
            ImrhoC [ offD_id_C_w ] = - rho * C_w[ offD_id_C_w ];
            // Calculate diagonal elements of ImrhoC
            ImrhoC [ D_id_C_w ] = 1 - rho * C_w[ D_id_C_w ];
            for(k in 1:K){
                A_S[,k] = csr_matrix_times_vector( M, M, ImrhoC, C_v, C_u, x_mat[,k] );
            }
        ldet_C = log1m( rho * C_eigenvalues );
        real sq_term = sum( A_R .* A_S' );
        return -0.5 * ( 
        M*K*log( 2 * pi() ) 
        +  ( 2 * M * sum( log_d_Sigma_R_chol ) - K * sum( ldet_C ) ) + sq_term 
        );
}
}

data{
	int<lower=1> M; 				// number of areas
	int y[M];
	vector[M] E;
	matrix[M, 2] X;
	// sparse components of C matrix
	vector[M] C_eigenvalues;
	int nC_w;
	vector[nC_w] C_w; 
	int C_v[nC_w]; 
	int C_u[M+1]; 
	int offD_id_C_w[nC_w - M];		// indexes for off diagonal terms
	int D_id_C_w[M]; 				// indexes for diagonal terms - length M
}
parameters{
	// precision and sigma must be matrices
	vector<lower=0>[1] tau2_v; // marginal variance
	real<lower=0,upper=1> rho;
	vector[2] bbeta;
	vector[M] phi;
}
transformed parameters{
	// To generalize the MLCAR we must use matrices
	matrix[M,1] phi_mat = to_matrix( phi, M, 1);
	// precision is inverse of tau2_v
	matrix[1,1] Omega_R = to_matrix( 1.0 ./ tau2_v, 1, 1 ); 
	// `Sigma_R` is covariance matrix
	matrix[1,1] Sigma_R = to_matrix( tau2_v, 1, 1 );
}
model{
	// likelihood model
	y ~ poisson_log(log(E) + X * bbeta + phi);
	
	// priors
	tau2_v[1] ~ inv_gamma( 1, 0.5); // variance
	bbeta ~ std_normal();
	rho ~ uniform( 0, 1);
	
	// unit Leroux CAR prior
	target += MLCAR_lpdf( phi_mat | rho, Omega_R, Sigma_R,
	C_w, C_v, C_u,     
	offD_id_C_w, D_id_C_w, C_eigenvalues, M, 1);
}
generated quantities{
real tau2 = tau2_v[1];
}
"
```

Fit model:
```{r, efficient_fit}
# data list
C_for_stan <- myfuns$prep4MCAR(W, type = "lcar")
C_for_stan$C <- NULL
d_stan <- list(M = nrow(data), y = data$observed,
               E = data$expected,
               X = X)
d_stan <- c(d_stan, C_for_stan)

# fit the Poisson Leroux model
m_s <- Sys.time()
s_fit <- sampling(object = s_comp, 
                  data = d_stan, 
                  pars = c("phi_mat", "tau2_v"), include = FALSE,
                  chains = 4, iter = 6000, warmup = 4000,
                  cores = 4, refresh = 0)
(s_rt <- as.numeric(Sys.time() - m_s, units = "mins"))

# summarize results
s_its <- rstan::extract(s_fit)
s_summ <- summarise_draws(s_fit) %>% 
  mutate(bess_pm = ess_bulk/s_rt,
         tess_pm = ess_tail/s_rt)
```

It took `r round(cb_rt, 2)`, `r round(sn_rt, 2)` and `r round(s_rt, 2)` minutes for the `CARBayes`, naive stan and efficient stan models, respectively.

# MCMC efficiency comparison

Using $\rho$. 

```{r, echo = FALSE}
# prepare data
ess_bulk <- c(cb_summ[cb_summ$variable == "rho",]$ess_bulk,
              sn_summ[sn_summ$variable == "rho",]$ess_bulk,
              s_summ[s_summ$variable == "rho",]$ess_bulk)
bess_pm <- c(cb_summ[cb_summ$variable == "rho",]$bess_pm,
              sn_summ[sn_summ$variable == "rho",]$bess_pm,
              s_summ[s_summ$variable == "rho",]$bess_pm)

# get data
eff <- data.frame(sampler = c("CARBayes", "Stan: naive", "Stan: efficient"),
                  ess_bulk = ess_bulk,
                  runtime_mins = c(round(cb_rt, 2), round(sn_rt, 2), round(s_rt, 2)),
                  bess_pm = bess_pm)
# rename columns
names(eff) <- c("Sampler", "Number of effective samples", "Elapsed time (mins)", "Effecti samples/minute")

# nice formatted table
kable(eff)
```


# Posterior distribution comparison

We'll compare the results for the hyper parameters.

```{r}
rbind(s_summ %>% 
  filter(str_detect(variable, "rho|bbeta|tau2")) %>% 
  mutate(variable = str_replace(variable, "bbeta", "beta"),
         variable = paste0(variable, " (stan)")),
cb_summ %>% 
  filter(str_detect(variable, "rho|beta|tau2")) %>% 
  mutate(variable = paste0(variable, " (cb)")),
sn_summ %>% 
  filter(str_detect(variable, "rho|bbeta|tau2")) %>% 
  mutate(variable = str_replace(variable, "bbeta", "beta"),
         variable = paste0(variable, " (stan naive)"))) %>% 
arrange(variable) %>% 
dplyr::select(variable, median, sd, rhat, ess_bulk, bess_pm)
```

```{r, echo = FALSE}
rbind(s_summ %>% 
  filter(str_detect(variable, "rho|bbeta|tau2")) %>% 
  mutate(variable = str_replace(variable, "bbeta", "beta"),
         sampler = "Stan: efficient"),
cb_summ %>% 
  filter(str_detect(variable, "rho|beta|tau2")) %>% 
  mutate(sampler = "CARBayes"),
sn_summ %>% 
  filter(str_detect(variable, "rho|bbeta|tau2")) %>% 
  mutate(variable = str_replace(variable, "bbeta", "beta"),
         sampler = "Stan: naive")) %>% 
ggplot(aes(x = median, xmin = q5, xmax = q95,
           y = variable, col = sampler))+
  theme_bw()+
  geom_errorbar(position = position_dodge(width=1))+
  geom_point(position = position_dodge(width=1))+
  labs(x = "", y = "Estimate",
       col = "")+
  coord_flip()
```

Below we compare the results for the first 9 elements of $\phi$. Take notice of the significant efficient gains that `CARBayes` provides for this simple example. 

```{r echo = FALSE}
rbind(s_summ %>% 
  filter(str_detect(variable, "phi\\[")) %>% 
  slice(1:9) %>% 
  mutate(variable = paste0(variable, " (stan)")),
sn_summ %>% 
  filter(str_detect(variable, "phi\\[")) %>% 
  slice(1:9) %>% 
  mutate(variable = paste0(variable, " (stan naive)")),
cb_summ %>% 
  filter(str_detect(variable, "phi\\[")) %>% 
  slice(1:9) %>% 
  mutate(variable = paste0(variable, " (cb)"))) %>% 
arrange(variable) %>% 
dplyr::select(variable, median, sd, rhat, ess_bulk, bess_pm)
```

We'll compare the results for the first 20 elements of $\phi$.

```{r, echo = FALSE}
rbind(s_summ %>% 
  filter(str_detect(variable, "phi\\[")) %>% 
  mutate(sampler = "Stan: efficient"),
cb_summ %>% 
  filter(str_detect(variable, "phi\\[")) %>% 
  mutate(sampler = "CARBayes"),
sn_summ %>% 
  filter(str_detect(variable, "phi\\[")) %>% 
  mutate(sampler = "Stan: naive")) %>% 
mutate(variable = as.numeric(str_remove(str_remove(variable, "phi\\["), "\\]"))) %>% 
  filter(variable < 21) %>% 
ggplot(aes(y = median, ymin = q5, ymax = q95,
           x = variable, col = sampler))+
  theme_bw()+
  geom_errorbar(position = position_dodge(width=1))+
  geom_point(position = position_dodge(width=1))+
  labs(x = "phi", y = "Estimate",
       col = "")+
  coord_flip()
```

# References

<div id="refs"></div>
